<?xml version='1.0' encoding='UTF-8'?>

<?xml-stylesheet href="./_c74_tut.xsl" type="text/xsl"?>

<chapter name="cage Tutorial 6: Virtual Fundamentals">

<openfile name="VirtualFundamentals" patch="VirtualFundamentals.maxpat"/>


<indexinfo category="Electrospectral" title="Virtual Fundamentals">Electrospectral</indexinfo>

<header>Tutorial 6: Virtual Fundamentals</header>

<body>In this tutorial, we will learn how to calculate the virtual fundamental of a chord, or the sequence of virtual fundamentals of all the chords in a score. We will also see that the algorithm that calculates a virtual fundamental can come handy in other, seemingly unrelated cases as well.
</body>

<subhead>Fundamentals</subhead>

<body>In some respects, there is no such thing as a fundamental. Whenever we hear a bassoon playing and we say "oh, this is an A" what actually happens is that our brain is trying to make sense of a very complicated pattern of air pressure variations coming to our ears. It turns out that these variations can be modeled as a sum of sinusoidal components whose frequencies are in some simple numerical relationships, although in most practical cases this is a quite rough approximation, at least for non-electronic instruments. Let say, just as an example, that the greatest part of the energy of our bassoon A can be roughly modeled as the sum of sine waves at the frequencies 110, 220.01, 329.95, 440.03, 549.87, 660.1, 770.82. You can hear this sound by turning on the audio and clicking on the cyan message box. Our brain will have no hesitation in saying that there is one note playing, and not seven, and that note is an A at approximately 110 Hz. Is this because the lowest component of the spectrum is indeed at 110 Hz? Not really, or not only. Actually, the sinusoidal component at 110 Hz can even be missing, or be extremely weak - try to listen to a bassoon low note from your laptop's loudspeakers, or click on the green message box! And still, our brain will recognize a fundamental frequency of 110 Hz, because all the frequencies that reach the ear according to our model are approximately multiples of 110 Hz. This is interesting for at least a couple of reasons: first, because 110 Hz, which we call A2 in the western musical theory, actually corresponds to the length of the air column that the bassoonist produced in his instrument; second, because 55 Hz, 27.5 Hz, 13.75 Hz and infinitely more other frequencies have the property of being approximate divisors of all the components of the original spectrum. But our brain picked the greatest possible, that is 110 Hz, and it did good - because of the air column thing, of course, that is, because this choice actually gives us information about the physics of the body that produced the sound: which, among the other things, helped our ancestors to distinguish between a cat passing by and a lion attacking them.</body>

<body>On the other hand, you can now go to your well-tuned piano and play the following notes: A2, A3, E4, A4, C#5 minus 14 cents, E5, G5 minus 49 cents: or approximate the experience by playing the cyan <o>bach.roll</o> object (to play a roll, just select it and press the space bar). Anyway, these notes correspond, more or less, to the frequencies 110, 220, 330, 440, 550, 660, 770 Hz: but what does my brain hear now? Well, it depends: if I am very good at playing all the notes perfectly together, it might happen that my brain detects a single sound source, with a fundamental of 110 Hz; otherwise, it will probably be able to make out the single notes composing the chord. In any case, the point we're trying to make here is: regardless of the physical nature of the body originating the sound. a concept of fundamental can be defined between any group of frequencies that can be closely enough arranged in simple enough ratios. And what does "enough" mean exactly? Well, it means exactly nothing: there is no strong divide between what can be considered as harmonic of a common fundamental, and what can't. In principle, an approximate common denominator can be found for every possible group of frequencies. It just might be too low: for example, there is no doubt that the frequencies 442, 662 and 1318 Hz have a precise common denominator of 2 Hz, but 2 Hz is definitely too low a frequency for us to hear, even with our "inner ear": so it is not a good candidate for a virtual fundamental. But if we accept a rougher approximation, we might discover that 442, 662 and 1318 Hz are all quite close to multiples of 220 Hz, that is 440, 660 and 1320 Hz. Now that's what our brain would probably decide upon hearing a sound composed by these frequencies: their fundamental must be more or less 220 Hz. And there can even be cases in which two or more potential fundamentals in the hearing range can be inferred, some higher, some more precise. Which will our brain pick? There is no definite rule: it depends on a variety of factors, ranging from physiology to education to the acoustic and musical context.</body>

<body>Indeed, there is an electroacoustic process which has often the tendency to make fundamentals pop up, whether they exist or not as actual components of a sound. This process is non-linear distortion. According to the shape of the distortion the results can be quite varied, but it is a fact that in most common cases this phenomenon is quite noticeable - try to listen the power chords at the beginning of "Smoke on the Water", or play the appropriately dark-red-and-gray <o>bach.score</o>. If the components of the signal that undergoes distortion have complex relations among them, more than one fundamental can be heard: and indeed sometimes you don't even need electroacoustics, as the non-linearity of the behavior of the eardrum can on some occasions cause sounds, especially if high-pitched and loud, to sound "distorted" and therefore fundamentals to be heard - just listen to some Maryanne Amacher at the appropriate volume!</body>



<subhead>Symbolic Virtual Fundamentals</subhead>
<body>All this being said, what is a symbolic virtual fundamental? If we take a chord, and find a note all the notes of the chord can be considered as approximate harmonics of, then we can call that note a virtual fundamental of the chord. the <b>cage</b> library contains a module for calculating virtual fundamentals: the <o>cage.virtfund</o> abstraction.</body>

<body>In its simplest usage, <o>cage.virtfund</o> receives a list of pitches and outputs one or more possible fundamentals, along with some parameters that may be useful to make sense of them. Let's try it: let's give <o>cage.virtfund</o> a C major chord, expressed by the pitches 6000 6400 6700, that is C4, E4, G4. Since a major chord in this position is quite close to the fourth, fifth and sixth harmonics of a note two octaves lowers than the chord's root tone, we expect the algorithm to return us something around C2, that is 3600 midicents. Indeed, if we click on the cyan message box we obtain an llll whose first element is a sublist containing the proposed fundamentals. In this case, there is only one: 3063.9 and odds, which definitely makes sense. The other elements oh the llll are a second sublist with the qualities of the fundamentals, that is number comprised between 0 and 1 giving an estimate of how precise the approximations are for each fundamental (in this case, it is very close to 1, which is quite good); and a third sublist containing some additional details for each fundamental: the reference harmonic and the pitch deviation of each note of the chord with respect to the harmonics of the fundamental.</body>

<body>We can also directly pass to <o>cage.virtfund</o> the output of a <o>bach.roll</o> or a <o>bach.score</o> object: in this case, we will be able to retrieve the virtual fundamentals computed with respect to time; the quality of each fundamental is converted into a velocity; and the details can be assigned to a slot, through the <m>detailsslot</m> attribute. You can try to edit the contents of the <o>bach.roll</o> object, and watch the result change in real time; you can also play the results with the space bar, as before, or listen to the two rolls played simultaneously by clicking the orange <b>play</b> message box.</body>



<subhead>Parameters, parameters, parameters</subhead>

<body>As we said, calculating a virtual fundamental is a complex task involving various choices and trade-offs. The <o>cage.virtfund</o> abstraction provides several attributes to control the details of the calculation: so, let's see how the algorithm works.</body>

<body>When a chord is entered, its lowest note is isolated, and an harmonic series is constructed upon it. At this point, the harmonic series is compared with the original chord, so as to see if some of the harmonics are good matches for the chord notes. This is done by finding, for each chord note, the nearest harmonic in the series, and calculating the distance between the two; then, some adjustment is done so as to distribute as evenly as possible the error among the components. In this way, we obtain a reference harmonic and a distance for each chord note, and a possible fundamental. Now we can make some considerations: is the fundamental too low? Are the orders of the partials too high? Is there a chord note which doesn't have a good match, because the maximum distance found is too wide? Is the chord globally not well matched, because the mean distance of each note from its reference harmonic is too wide? Or, on the contrary, is the chord extremely well matched? According to the answers to these questions, we can choose to retain this fundamental, or to discard it; in the first case, we must assign it a score: ideally, we should reward candidates with a small mean distance and not too high-ordered harmonics, but how do these two criteria interact? Once all this is settled, if we didn't reach a too high partial we can try another possible fundamental: to do so, we consider the lowest note of the chord as the second harmonic, which is to say that the tested fundamental will have a frequency that will be half the frequency of the lowest note of the chord, and we repeat the process; after that, the algorithm tries with a fundamental with frequency 1/3, then 1/4 and so on. Or, we can decide that the fundamental was so good that we stop the search here. At some point the process ends, because even if no good solution is found a too high partial is eventually  reached, and we can output the results of the search.</body>

<body>So, what are the parameters of the algorithm? Let's run quickly through the algorithm description, and find out: the lowest allowed fundamental ("Is the fundamental too low?"); the highest allowed partial ("Are the orders of the partials too high?"); the greatest allowed maximal distance ("Is there a chord note which doesn't have a good match?"); the greatest allowed mean distance ("Is the chord globally not well matched?"); what is the mean distance that should be considered immediately satisfying, and therefore stop the search ("Is the chord extremely well matched?"); and the relative influence of the exactness and the pitch of each virtual fundamental on its score ("how do these two criteria interact?"). The good news is, there is an attribute for each of these parameters. The name of the attributes are the following: <m>minfund</m>, <m>maxpartial</m>, <m>maxmaxdist</m>, <m>maxmeandist</m>, <m>ultmeandist</m>,  <m>distanceweight</m>, <m>partialweight</m>. There is one more attribute, <m>maxcount</m>, setting a maximum number of fundamentals to be returned: if more fundamentals than <m>maxcount</m> are found, the ones with the lowest scores will be discarded.</body>

<body>Now, try to select some preset, retrigger the computation and see how modifying the values of the attributes change the result.</body>


<subhead>Advanced applications</subhead>

<body>As said above, the computation of virtual fundamentals is a special case of a more general problem: the estimation of an approximate greatest common divisor among a set of numbers. Actually, <o>cage.virtfund</o> can help in this task, by setting the <m>raw</m> attribute to 1: in this way, all the input and output data are expressed in absolute terms, rather than midicents, including the distance attributes, which express ratios rather than pitch intervals.</body>

<body>A process that can be represented within this framework is the estimation of a minimal rhythmic unit in a <o>bach.roll</o>. Let's suppose that we have a note from 0 to 300 ms; another note from 200 to 300 ms; and another note from 500 to 600 ms. We want to find a rhythmic subdivision upon which all the beginning and ends of the notes can fall, within some approximation. In the above example, it is clear this grid should have a resolution of 100 ms, that is the greatest common divisor of 200, 300, 500 and 600.</body>

<body>Now as soon as we introduce the need for some approximation the problem becomes trickier: since now the quality of a solution is evaluated using distance ratio, it turns out that towards the end of a score, where numbers are higher, the absolute error will be allowed to be wider.</body>

<body>So, what we'll do will be operating on not only on the absolute times, but also on the time distances, in order to give our algorithm more elements to work upon. In our example, the distance between 0 and 300 ms is 300 ms; the distance between 200 and 300 is 100 ms; and so on. We have to take care of removing the duplicates and the zeros, but that's easy thanks to the <o>bach.thin</o> and <o>bach.sieve</o> modules. It is interesting to remark that what looked like a weak point, the fact that higher values allow looser tolerances in absolute terms, is now a strength, since it will mean that sparser areas of the score will be allowed to deviate more from the grid than denser areas.</body>

<body>Now let's have a look at the subpatch called "temporal fundamental", which is where the actual task is performed: we ask <o>bach.roll</o> to output the temporal data it contains, that is the onsets of all its chords and the durations of all its notes. Starting from this data, we can build a temporal map of the score: we iterate the chords one by one with bach.mapchord, and for each chord we collect its onset, as well as the sum of its onset and the duration of each of the notes it contains. Then we sort the map, remove the duplicate elements and we can retrieve the intervals between the temporal positions it contains, using <o>bach.x2dx</o>, and join together the list of the time distances and the list of the absolute times.</body>

<body>Now the fun part begins: we ask <o>cage.virtfund</o> to estimate a possible temporal subdivision of the score. To do so, we need to set the <m>raw</m> attribute to 1 (we're dealing with ms, not pitches), and some appropriate values for the other attributes. Let's review them: <b>minfund 10</b> means that the smallest subdivision we accept is 10 ms; <b>maxpartial 500</b> means that the ratio between the longest time interval in the score and the found subdivision is not allowed to be more than about 500:1 (remember: everything here is approximate); <b>ultmeandist 1</b> means that the computation is allowed to stop before examining all the possibilities only if an exact solution is found (1 means that the mean ratio between the exact multiples of the time interval and the actual values must be 1:1, that is they have to be the same); <b>maxmaxdist 1.1</b> and <b>maxmeandist 1.05</b> mean respectively that a 10% maximal error and a 5% mean error are allowed. In the end, we retrieve from the output of <o>cage.virtfund</o> the value we're interested in, that is the first element of the first sublist - which here will anyway contain a single element, since we have left <m>maxcount</m> to its default of 1 - and we use this value to set the displayed grid of <o>bach.roll</o>.</body>

<subhead>Conclusion</subhead>

<body>The <o>cage.virtfund</o> module is a powerful tool mainly conceived to solve an interesting musical task, which can for example suggest interesting "root tones" or bass notes for non-standard harmonic aggregates. Besides this, by carefully tweaking the various attributes available it is possible to use <o>cage.virtfund</o> for other, significantly different tasks.</body>

<seealsolist>
<seealso name="cage.rm">Compute symbolic ring modulation</seealso>
<seealso name="cage.fm">Compute symbolic frequency modulation</seealso>
<seealso name="cage.harmser">Compute harmonic series</seealso>
<seealso name="overdrive~">Audio non-linear distortion module</seealso>
</seealsolist>

</chapter>
