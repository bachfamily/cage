<?xml version='1.0' encoding='UTF-8'?>

<?xml-stylesheet href="./_c74_tut.xsl" type="text/xsl"?>

<chapter name="cage Tutorial 5: Ring and Frequency Modulation">

<openfile name="RingAndFrequencyModulation" patch="RingAndFrequencyModulation.maxpat"/>


<indexinfo category="Electrospectral" title="Ring and Frequency Modulation">Electrospectral</indexinfo>

<header>Tutorial 5: Ring and Frequency Modulation</header>

<body>In this tutorial, we will learn two closely related techniques to make two chunks of musical material interact with each other and produce rich and interesting harmonic structures.</body>
<body><openpatchlink>Open the tutorial patch</openpatchlink></body>

<subhead>Ring modulation</subhead>

<body>Ring modulation is one of the most ancient signal processing techniques.
It is closely related to amplitude modulation and tremolo, so we'll review those first. Tremolo is how we call a periodic change in the amplitude of an audio signal, so that we perceive the amplitude itself rising and falling and rising again and falling and so on over time. There is an extensive MSP tutorial about this, but let's open the patch, look at the green section, turn on the <o>ezdac~</o>. The patch is simple: an audio-rate oscillator, the red <o>cycle~</o>, has its output multiplied by a low frequency oscillator, the cyan <o>cycle~</o>. Indeed, multiplying and audio signal by something is a way to control its amplitude, and multiplying by something that changes over time such an LFO is a way to make its amplitude change over time. By the way, we'll call the signal produced by red oscillator the <b>carrier</b>, as it carries the most important information (that is, the frequency that we want to hear), and the signal produced by the cyan oscillator the <b>modulating</b>, as it modulates a parameter of the carrier (its amplitude, in this case). There is just one more detail: the output of <o>cycle~</o> varies between -1 and 1, but as long as we want to preserve the signal phase we only control amplitude with values between 0 and 1. This is why we rescale the output of the cyan <o>cycle~</o> with a <o>scale~</o> object: we say that we make the signal coming from the cyan <o>cycle~</o> <b>unipolar</b>.</body>

<body>Now, we can hear very well that vibrato is essentially a rhythmic phenomenon. But as we know, rhythm and pitch are made from the same substance, that is stuff happening in time. So we might wonder what happens if we raise the frequency of the cyan oscillator from 3 Hz, that is something we perceive as rhythm, to say 110 Hz, that is something we perceive as pitch. Let's just type <m>110</m> in the cyan number box. Oh, that's weird: there is no rhythm anymore: instead, we hear a perfect A major chord in second inversion! There are very good mathematical reasons for this, but we'll not review them here - you can find all the serious demonstrations in any good book about signal processing, such as Miller Puckette's "The Theory and Technique of Electronic Music". We'll just say that we are hearing three frequencies now, and these frequencies are the frequency of the modulating signal, that is 440; the frequency of the modulating signal minus the frequency of the carrier signal, that is 440 - 110 = 330; and the the frequency of the modulating signal plus the frequency of the carrier signal, that is 440 + 110 = 550. Now we know that 440 is A4; 330 is 3/4 of 440, that is a natural perfect fourth below A4; and 550 is 5/4 of 440, that is a natural major third above A4: here is our natural E-A-C# chord! (N.B.: the frequencies we obtained don't exactly correspond to the tempered E and C#, so if you try to feed them to <o>bach.f2mc</o> the midicent values you will obtain will slightly deviate from 6400 and 7300).</body>

<body>We're almost there: what we just produced is called amplitude modulation (or AM) synthesis. If you wonder whether there is a relation with AM radio, yes, there is, but we'll not investigate it now! Now let's shut AM down, and let's turn to the orange-ish section of the patch. As you can see, the patch is essentially the same, except for the fact that there is no <o>scale~</o> object anymore: the  signal produced by the cyan <o>cycle~</o> is kept unaltered, to its original -1...1 <b>bipolar</b> range. So what do we hear now? No more triad, but just a major sixth: there is no more A, just the E and C#. Indeed, if two bipolar signals are modulated together they produce the sum and the difference of their frequencies, but the original frequencies disappear: so here we have only two resulting components, at 440 - 110 = 330 Hz and 440 + 110 = 550 Hz. This multiplication of two bipolar audio signals is called <b>ring modulation</b>, or RM, because of the configuration of the analog circuit that was originally used to produce it. We can notice that, since multiplying <b>110</b> by <b>440</b> or <b>440</b> by <b>110</b> is exactly the same, there is no actual distinction between a carrier and a modulating component anymore: we only have two interchangeable contributing signals.</body>

<body>Now let's do a couple more things: let's change the frequencies of our oscillators and have a look to the <o>bach.ratnum</o> object below: it's easy to see that simple ratios between the two frequencies produce more "harmonic" or "consonant" results (mind the double quotes!), and more complex ratios produce more "inharmonic" or "dissonant" results. And finally, let's switch to the magenta section of the patch, which once again is very similar to the orange one, except for the fact that the oscillators are no more <o>cycle~</o> objects, but <o>saw~</o>. What we're doing now is that we're modulating two signals that are harmonically rich, that is composed by a large number of sinusoidal components. What do we hear now? Much more richness, and much more inharmonicity if the ratio gets more complex! This happens because if we modulate composite signals with each other, each sinusoidal component of the first signal will be modulated against each sinusoidal component of the second signal, and viceversa. So, if for example we have two signals composed by 10 sinusoidal components each, the ring-modulated signal will contain 10 * 10 = 100 sinusoidal components. In fact, in most simple cases some of these 100 components will overlap, and when two components overlap they can result in a single, stronger component or in a weaker component, according to their phase relation; it can even turn out that the weaker component is so weak that it disappears completely. But long story short, we have a way to take two groups of sinusoids and make them interact in a way to create a signal that is potentially much richer than just the plain sum of the two.</body>


<subhead>Frequency modulation</subhead>

<body>There is another important technique, quite similar to ring modulation, to obtain rich signals from simple signals: frequency modulation. Indeed, the signals produced by frequency modulation are potentially much richer that those produced by ring modulation. The idea here is that two sinusoids interacting don't produce just a single sum/difference couple; rather, they produce a theoretically infinite sum/difference series. We must bring back the concepts of carrier and modulating, because the process is not commutative (that is, the result changes if you switch the parameters): the signal resulting by this particular type of modulation will contain components at the carrier frequency, the carrier plus the modulating frequency, the carrier plus twice the modulating frequency, the carrier plus three times the modulating frequency, and then four times, five times and so on; and also, the carrier minus the modulating frequency, the carrier minus twice the modulating frequency, and so on. At some point we end up producing negative numbers, which actually represent components whose phase is reversed - and which subsequently may annihilate components with positive frequencies. As we said, this series is theoretically infinite, but from a practical point of view it can be seen as finite as the amplitudes of the components decrease with the distance from the carrier frequency, according to some rather exotic mathematical functions called the Bessel functions: so, at some point we won't be able to hear them anymore, and anyway at some point our digital audio system won't be able to compute them anymore.</body>

<body>This modulation technique is called <b>frequency modulation</b>, or FM, and yes, it is related to FM radio in ways we won't discuss. It was extensively studied by John Chowning at the Stanford University during the '70s, and has been implemented in a huge number of synthesizers because of its sonic richness and flexibility. The cyan section of the patch shows a minimal example of a FM synthesizer: as you can see, the idea is that the modulating signal actually controls the frequency of the carrier signal. The green number box provides an additional control, called the modulation index: to keep it simple, let's say that it a sonically significant way to control the amplitude of the modulating signal, and it is defined as the ratio between the modulating amplitude and the carrier frequency. If the blue and green number boxes are set to small values, what we get is a vibrato. But if we raise them respectively to, say, 110 and 1 we get awesomeness - and, according to your musical preferences, it might get even better if you set the two frequencies to some inharmonic ratio! Also, try to change the modulation index: as you can hear, a higher modulation index results in a richer sound, but there is no direct linear relation. Considering that it only takes two oscillators to obtain all this, you can easily see why FM synthesis immediately became a complete game changer when it appeared in the reasonably priced Yamaha DX-7 synthesizer in the '80s.</body>


<subhead>Symbolic ring and frequency modulation</subhead>

<body>Now a question arises: if we have such interesting ways to generate sounds, and we know all the underlying math, why not bend them to produce symbolic material? Indeed, generations of composers, especially but not solely linked to the French spectral movement and the teachings of Tristan Murail, have been using since decades harmonic techniques derived from ring and frequency modulation. The basic idea is that we can take two chords and consider them as if they were audio signal, whose components correspond to the notes constituting the chord. Once we have defined these signals, we know how to calculate the result of their ring modulation (which is relatively simple) and their frequency modulation (which is somehow more complicated): so we can generate a new chord whose notes correspond to the sinusoidal components of either type of modulation.</body>

<body><b>cage</b> contains two abstractions, <o>cage.rm</o> and <o>cage.fm</o>. Their basic usage is simple: they take two chords, expressed as pitch/velocity sublists, and produce another chord which is the result of the modulation. Or they take the contents of two <o>bach.roll</o>, and produce another roll representing how the two original rolls modulate each other over time. Or they take the contents of two <o>bach.score</o> objects, or one <o>bach.roll</o> and one chord, or one <o>bach.score</o> and a chord, and do the same.</body>

<body>The <o>cage.fm</o> abstraction also allows controlling the modulation index, either by setting a fixed one as the patcher argument or in the third inlet, or through a lambda loop: in the latter case, the velocities of the modulating chord, roll or score are output and the lambda loop will convert each of them into a modulation index - after all, we saw that the modulation index is related to the amplitude of the modulating components.</body>

<body>By connecting the rightmost outlet of <o>bach.roll</o> or <o>bach.score</o> to a <m>dump</m> message that is re-injected in the object's first inlet, we can ensure that at every modification the contents of the object are sent out of its outlets, so as to trigger processes depending on them. Moreover, if the <m>continuouslyoutputbangifchanged</m> attribute is set to 1 (which is in this example), the notification from the rightmost outlet is sent not only at the end of each mouse dragging action, but also during the action itself, thus allowing among the other things to follow in real time score elements as they are moved around. So, we can try to change the contents of the <m>bach.roll</m> objects, and see the modulations changing accordingly. In this example, we also map velocities from 0 to 127 to modulation indexes from 0.1 to 3, through a <m>bach.scale</m> module connected to the lambda inlet. Notice that the velocities are shown in the original and resulting rolls thanks to the <m>velocityhandling</m> attribute.</body>

<body>There are some subtleties to take into account, though: first, musical notation treats rhythm and pitch as two totally independent, orthogonal parameters, but in signal processing they are essentially the same entity. This leads to some problems: for example, what happens if we obtain two components at 440 and 440.5 Hz? In an audio process we would hear a beating, a rhythmic phenomenon. But here we want to generate chords, not rhythms: so we will choose to consider components that are very close to each other as one single component. Also, audio modulations can easily produce very low, inaudible frequencies or DC offsets. Most audio systems have built-in high-pass filters, so these frequencies generally don't pose any problem: but here we need to deal with them, and get rid of them, explicitly. Finally, when a modulation is calculated in time it is not always obvious to decide whether two consecutive notes should actually be considered as one single, longer note. The <o>bach.rm</o> and <o>bach.fm</o> abstractions provide attributes to deal with these cases - respectively, the <m>freqthresh</m>, <m>minfreq</m> and <m>glue</m> attributes. In general, though, you can probably stick to their standard settings.</body>



<subhead>Conclusion</subhead>

<body>Ring modulation and frequency modulation are powerful signal processing techniques, which can meaningfully be ported to the domain of symbolic musical notation. Through the <o>bach.rm</o> and <o>bach.fm</o> abstractions, respectively implementing these two processes, chords and scores can be modulated so as to produce rich and highly controllable harmonic material in time.</body>

<seealsolist>
<seealso name="cage.virtfund">Compute symbolic virtual fundamentals</seealso>
<seealso name="cage.harmser">Compute harmonic series</seealso>
</seealsolist>
</chapter>
